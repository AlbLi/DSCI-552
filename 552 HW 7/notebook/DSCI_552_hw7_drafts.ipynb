{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c48d373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "import csv\n",
    "import pandas as pd\n",
    "from scipy.stats import bootstrap\n",
    "import statistics\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c4feba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7194</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7195 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4   5   6   7   8   9   ...  12  13  14  15  16  17  18  \\\n",
       "0      1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "1      1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "2      1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "3      1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "4      1   1   0   0   0   0   0   0   0   0  ...   0   1   0   0   0   0   0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
       "7190   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "7191   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "7192   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "7193   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "7194   0   0   0   0   0   0   0   0   0   1  ...   0   0   0   0   0   0   0   \n",
       "\n",
       "      19  20  21  \n",
       "0      0   0   0  \n",
       "1      0   0   0  \n",
       "2      0   0   0  \n",
       "3      0   0   0  \n",
       "4      0   0   0  \n",
       "...   ..  ..  ..  \n",
       "7190   0   1   1  \n",
       "7191   0   1   1  \n",
       "7192   0   1   1  \n",
       "7193   0   1   1  \n",
       "7194   0   1   1  \n",
       "\n",
       "[7195 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frogs = pd.read_csv('../data/Frogs_MFCCs.csv')\n",
    "# Separate the features (X) and labels (y)\n",
    "X = frogs.iloc[:, :-4]\n",
    "y = frogs[['Family', 'Genus', 'Species', 'RecordID']]\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_b = mlb.fit_transform(y.iloc[:,:-1].values)\n",
    "y_b = pd.DataFrame(y_b)\n",
    "y_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73bc3ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.06299212598425197\n",
      "Hamming score: 0.937007874015748\n",
      "EMR: 0.937007874015748\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = frogs\n",
    "\n",
    "# Split the data into input features X and class labels y\n",
    "X = data.iloc[:, :-4]\n",
    "y = data.iloc[:, -4]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the SVM model with OvA method\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "\n",
    "    \n",
    "# Calculate the Hamming Loss\n",
    "hl = hamming_loss(y_test, y_pred)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "# Calculate the Hamming Score\n",
    "print(\"Hamming score:\", 1-hl)\n",
    "\n",
    "# Calculate the Exact Match Ratio (EMR)\n",
    "emr = accuracy_score(y_test, y_pred)\n",
    "print(\"EMR:\", emr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eddfd642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.04955998147290412\n",
      "Hamming score: 0.9504400185270959\n",
      "EMR: 0.9504400185270959\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = frogs\n",
    "\n",
    "# Split the data into input features X and class labels y\n",
    "X = data.iloc[:, :-4]\n",
    "y = data.iloc[:, -3]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the SVM model with OvA method\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "\n",
    "    \n",
    "# Calculate the Hamming Loss\n",
    "hl = hamming_loss(y_test, y_pred)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "# Calculate the Hamming Score\n",
    "print(\"Hamming score:\", 1-hl)\n",
    "\n",
    "# Calculate the Exact Match Ratio (EMR)\n",
    "emr = accuracy_score(y_test, y_pred)\n",
    "print(\"EMR:\", emr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddea5595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.030569708198239925\n",
      "Hamming score: 0.9694302918017601\n",
      "EMR: 0.9694302918017601\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "data = frogs\n",
    "\n",
    "# Split the data into input features X and class labels y\n",
    "X = data.iloc[:, :-4]\n",
    "y = data.iloc[:, -2]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the SVM model with OvA method\n",
    "svm = SVC(kernel='linear', decision_function_shape='ovr')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "\n",
    "    \n",
    "# Calculate the Hamming Loss\n",
    "hl = hamming_loss(y_test, y_pred)\n",
    "print(\"Hamming Loss:\", hl)\n",
    "\n",
    "# Calculate the Hamming Score\n",
    "print(\"Hamming score:\", 1-hl)\n",
    "\n",
    "# Calculate the Exact Match Ratio (EMR)\n",
    "emr = accuracy_score(y_test, y_pred)\n",
    "print(\"EMR:\", emr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe45bf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standart Deviation of 50 Hamming Distances : 0.011313237513617935\n",
      "Average of the 50 Hamming Distances : 0.7751484827426454\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import hamming_loss\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "\n",
    "# Loading the DATA\n",
    "all_data = pd.read_csv('../data/Frogs_MFCCs.csv')\n",
    "all_data=all_data.drop('RecordID',axis=1)\n",
    "\n",
    "\n",
    "cols=[e for e in all_data if e not in ( 'Family','Genus','Species')]\n",
    "X=all_data.loc[:,cols]\n",
    "Y=all_data.loc[:, ['Family','Genus','Species']]\n",
    "\n",
    "final_ham_loss=[]\n",
    "final_ham_score=[]\n",
    "\n",
    "fam_maj_trip={p:[] for p in range(1,51)}\n",
    "genus_maj_trip={p:[] for p in range(1,51)}\n",
    "species_maj_trip={p:[] for p in range(1,51)}\n",
    "#-----------------------------------------------------------------------------\n",
    "# Monte Carlo Simulation- Performing the procedure 50 times\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "for cls in range(1,51):\n",
    "    silh_avg = dict()\n",
    "#-----------------------------------------------------------------------------    \n",
    "# Finding the Optimal K value between 2-20 automatically using SilHoutte Average\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    for k in range(2,20):\n",
    "        rand_value=random.randint(0, 900)\n",
    "        k_means = KMeans(n_clusters=k,init='k-means++',random_state=rand_value).fit(X)\n",
    "        labels = k_means.labels_\n",
    "        silh_avg.update({k:(metrics.silhouette_score(X, labels))})\n",
    "   \n",
    "    #print(\"Iteration : \",cls)\n",
    "    #print(\"Average Silhoutte score values : \",silh_avg)\n",
    "#-----------------------------------------------------------------------------   \n",
    "# Selecting the K-value with the maximum Silhoutte Score\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    optimal_k = max(silh_avg,key=silh_avg.get)\n",
    "    \n",
    "    rand_value=random.randint(0, 900)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Performing K-means Clustering For Optimal K-value Found\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    X1=X\n",
    "    k_means_f = KMeans(n_clusters=4, random_state=rand_value).fit(X1)\n",
    "    cluster_labels = k_means_f.labels_\n",
    "\n",
    "    clusters = pd.concat([X1,Y,pd.DataFrame({'labels':cluster_labels.tolist()})],axis = 1)\n",
    "    clusters['labels'].value_counts()\n",
    "\n",
    " \n",
    "    #print(\"Optimal Cluster value : \",optimal_k)\n",
    "    for k in range(4):\n",
    "        find= clusters[clusters['labels']==k]\n",
    "        #print('Cluster',k+1)\n",
    "        #print('\\nMajority class in family - ',find['Family'].value_counts().index[0])\n",
    "        #print('Majority class in genus - ',find['Genus'].value_counts().index[0])\n",
    "        #print('Majority class in species - ',find['Species'].value_counts().index[0])\n",
    "        #print('\\n')\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Determining the Majority Triplet for each Cluster\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    maj_trip = {k:[] for k in range(4)}\n",
    "    for k in range(4):\n",
    "        c_value = clusters[clusters['labels']==k]\n",
    "        maj_trip[k].append(c_value['Family'].value_counts().index[0])\n",
    "        maj_trip[k].append(c_value['Genus'].value_counts().index[0])\n",
    "        maj_trip[k].append(c_value['Species'].value_counts().index[0])\n",
    "        fam_maj_trip[cls].append(c_value['Family'].value_counts().index[0])\n",
    "        genus_maj_trip[cls].append(c_value['Genus'].value_counts().index[0])\n",
    "        species_maj_trip[cls].append(c_value['Species'].value_counts().index[0])\n",
    "\n",
    "    \n",
    "    clusters['family_pred'] = 'none'\n",
    "    clusters['genus_pred'] = 'none'\n",
    "    clusters['species_pred'] = 'none'\n",
    "\n",
    "    for k in range(4):\n",
    "        clusters['family_pred'] = np.where(clusters['labels']==k,maj_trip[k][0],clusters['family_pred'])\n",
    "        clusters['genus_pred'] = np.where(clusters['labels']==k,maj_trip[k][1],clusters['genus_pred'])\n",
    "        clusters['species_pred'] = np.where(clusters['labels']==k,maj_trip[k][2],clusters['species_pred'])\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Calculating the Average Hamming Score\n",
    "#-----------------------------------------------------------------------------\n",
    "    fam_s=hamming_loss(clusters['Family'],clusters['family_pred'])\n",
    "    gen_s=hamming_loss(clusters['Genus'],clusters['genus_pred'])\n",
    "    spec_s=hamming_loss(clusters['Species'],clusters['species_pred'])\n",
    "\n",
    "    ham_loss_s=(fam_s+gen_s+spec_s)/3\n",
    "\n",
    "    #print(\"Hamming Loss : \",np.round(ham_loss_s,6))\n",
    "    #print(\"Hamming Score : \",1-ham_loss_s)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# Calculating the average and standard deviation of the 50 Hamming Distances \n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "    final_ham_loss.append(np.round(ham_loss_s,6))\n",
    "    final_ham_score.append((1-ham_loss_s))\n",
    "\n",
    "\n",
    "print(\"Standart Deviation of 50 Hamming Distances : {}\".format(statistics.stdev(final_ham_score)))\n",
    "\n",
    "print(\"Average of the 50 Hamming Distances : {}\".format(statistics.mean(final_ham_score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b5dd017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Hamming distance:  30.0\n",
      "Standard deviation of Hamming distance:  25.666666666666668\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "y = frogs[['Family', 'Genus', 'Species']]\n",
    "hamming_distances = {label: [] for label in y.columns}\n",
    "hamming_distances['Family'].append(92)\n",
    "hamming_distances['Genus'].append(2)\n",
    "hamming_distances['Species'].append(9)\n",
    "hamming_distances['Family'].append(2)\n",
    "hamming_distances['Genus'].append(26)\n",
    "hamming_distances['Species'].append(49)\n",
    "mean_dict = {}\n",
    "std_dict = {}\n",
    "for label in y.columns:\n",
    "    mean_dist = np.mean(hamming_distances[label])\n",
    "    std_dist = np.std(hamming_distances[label])\n",
    "    mean_dict[label] = mean_dist\n",
    "    std_dict[label] = std_dist\n",
    "\n",
    "mean_hamming_distances = sum(mean_dict.values())/len(mean_dict)\n",
    "sd_hamming_distances = sum(std_dict.values())/len(std_dict)\n",
    "print(\"Average Hamming distance: \", mean_hamming_distances)\n",
    "print(\"Standard deviation of Hamming distance: \", sd_hamming_distances)\n",
    "\n",
    "print((np.mean(hamming_distances['Family'])+\n",
    "np.mean(hamming_distances['Genus'])+\n",
    "np.mean(hamming_distances['Species']))/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74809b92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bl/cyzb7l7939lg7l3437y92vc00000gn/T/ipykernel_1678/512332507.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msilh_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Silhouette score values:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilh_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import hamming_loss, hamming_score, hamming_loss\n",
    "\n",
    "# Perform the procedure 50 times\n",
    "n_iter = 50\n",
    "mean_hamming_distances = []\n",
    "mean_hamming_scores = []\n",
    "mean_hamming_losses = []\n",
    "\n",
    "#for i in range(n_iter):\n",
    "# Find optimal number of clusters using Silhouette score\n",
    "sil_scores = []\n",
    "for k in range(2, 21):\n",
    "    rand_value = np.random.randint(0, 100)\n",
    "    k_means = KMeans(n_clusters=k, init='k-means++', random_state=rand_value).fit(X)\n",
    "    labels = k_means.labels_\n",
    "    silh_avg.update({k: (metrics.silhouette_score(X, labels))})\n",
    "\n",
    "print(\"Iteration:\", i+1)\n",
    "print(\"Average Silhouette score values:\", silh_avg)\n",
    "\n",
    "# Get optimal k and build K-means clustering with it\n",
    "optimal_k = max(silh_avg, key=silh_avg.get)\n",
    "rand_value = np.random.randint(0, 900)\n",
    "print(\"Optimal k:\", optimal_k)\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=rand_value)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Determine majority triplet for each cluster\n",
    "majority_triplets = []\n",
    "for j in range(optimal_k):\n",
    "    cluster_labels = kmeans.labels_ == j\n",
    "    cluster_y = y[cluster_labels]\n",
    "    majority_triplet = (cluster_y.mode().iloc[0, 0], cluster_y.mode().iloc[0, 1], cluster_y.mode().iloc[0, 2])\n",
    "    majority_triplets.append(majority_triplet)\n",
    "\n",
    "# Predict target variables using majority triplet\n",
    "predicted_y = np.array([majority_triplets[label] for label in kmeans.labels_])\n",
    "\n",
    "# Calculate Hamming distance, Hamming score, and Hamming loss for each label\n",
    "hamming_distances = []\n",
    "hamming_scores = []\n",
    "hamming_losses = []\n",
    "for label in range(num_labels):\n",
    "    hamming_distances.append(hamming_loss(y[:, label], predicted_y[:, label]))\n",
    "    hamming_scores.append(hamming_score(y[:, label], predicted_y[:, label]))\n",
    "    hamming_losses.append(hamming_loss(y[:, label], predicted_y[:, label]))\n",
    "\n",
    "# Calculate mean Hamming distance, Hamming score, and Hamming loss across all labels\n",
    "mean_hamming_distances.append(np.mean(hamming_distances))\n",
    "mean_hamming_scores.append(np.mean(hamming_scores))\n",
    "mean_hamming_losses.append(np.mean(hamming_losses))\n",
    "\n",
    "# Calculate overall mean and standard deviation of Hamming distances, Hamming scores, and Hamming losses\n",
    "mean_hamming_distance = np.mean(mean_hamming_distances)\n",
    "std_hamming_distance = np.std(mean_hamming_distances)\n",
    "\n",
    "mean_hamming_score = np.mean(mean_hamming_scores)\n",
    "std_hamming_score = np.std(mean_hamming_scores)\n",
    "\n",
    "mean_hamming_loss = np.mean(mean_hamming_losses)\n",
    "std_hamming_loss = np.std(mean_hamming_losses)\n",
    "\n",
    "print(\"Mean Hamming distance:\", mean_hamming_distance)\n",
    "print(\"Standard deviation of Hamming distance:\", std_hamming_distance)\n",
    "\n",
    "print(\"Mean Hamming score:\", mean_hamming_score)\n",
    "print(\"Standard deviation of Hamming score:\", std_hamming_score)\n",
    "\n",
    "print(\"Mean Hamming loss:\", mean_hamming_loss)\n",
    "print(\"Standard deviation of Hamming loss:\", std_hamming_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4147d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
