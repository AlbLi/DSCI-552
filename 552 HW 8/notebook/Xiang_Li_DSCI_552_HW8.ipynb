{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0dde94",
   "metadata": {},
   "source": [
    "## Author: Xiang (Albert) Li\n",
    "## USC ID: 1892796881\n",
    "## Github Userid: XiangLi1209\n",
    "## Created Time: Apr 11th, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647df918",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2ed357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "import sklearn.metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "import copy\n",
    "import shutil\n",
    "import urllib.request\n",
    "import csv\n",
    "from scipy.stats import bootstrap\n",
    "import statistics\n",
    "from PIL import Image\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss,silhouette_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffa21b1",
   "metadata": {},
   "source": [
    "### 1. Supervised, Semi-Supervised, and Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898f7a5",
   "metadata": {},
   "source": [
    "#### (a) Download the Breast Cancer Wisconsin (Diagnostic) Data Set from: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29. Download the data in https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data, which has IDs, classes (Benign=B, Malignant=M), and 30 attributes. This data has two output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19bfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\"\n",
    "column_names = [\n",
    "    'id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "    'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "    'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "    'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "    'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "    'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "    'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "    'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "    'symmetry_worst', 'fractal_dimension_worst'\n",
    "]\n",
    "\n",
    "cancer = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "print(cancer.head())\n",
    "X = cancer.iloc[:, 2:].values\n",
    "y = (cancer.iloc[:, 1] == 'M').astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2e00a59",
   "metadata": {},
   "source": [
    "#### (b) Monte-Carlo Simulation: Repeat the following procedures for supervised, unsupervised, and semi-supervised learning M = 30 times, and use randomly selected train and test data (make sure you use 20% of both the positve and negative classes as the test set). Then compare the average scores (accuracy, precision, recall, F1-score, and AUC) that obtain from each algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d297b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores: {'accuracy': 0.989010989010989, 'precision': 0.9940119760479041, 'recall': 0.9764705882352941, 'f1_score': 0.9851632047477744, 'auc': 0.9864809081527348}\n",
      "Test scores: {'accuracy': 0.9736842105263158, 'precision': 0.9534883720930233, 'recall': 0.9761904761904762, 'f1_score': 0.9647058823529412, 'auc': 0.9742063492063492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/alberli/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Train L1-penalized SVM\n",
    "param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "l1_svm = LinearSVC(penalty='l1', dual=False, max_iter=5000)\n",
    "grid = GridSearchCV(l1_svm, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "best_model = grid.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_scores = {\n",
    "    'accuracy': accuracy_score(y_train, y_train_pred),\n",
    "    'precision': precision_score(y_train, y_train_pred),\n",
    "    'recall': recall_score(y_train, y_train_pred),\n",
    "    'f1_score': f1_score(y_train, y_train_pred),\n",
    "    'auc': roc_auc_score(y_train, y_train_pred)\n",
    "}\n",
    "\n",
    "test_scores = {\n",
    "    'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "    'precision': precision_score(y_test, y_test_pred),\n",
    "    'recall': recall_score(y_test, y_test_pred),\n",
    "    'f1_score': f1_score(y_test, y_test_pred),\n",
    "    'auc': roc_auc_score(y_test, y_test_pred)\n",
    "}\n",
    "\n",
    "print(\"Train scores:\", train_scores)\n",
    "print(\"Test scores:\", test_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eca948",
   "metadata": {},
   "source": [
    "#### i. Supervised Learning: Train an L1-penalized SVM to classify the data. Use 5 fold cross validation to choose the penalty parameter. Use normalized data. Report the average accuracy, precision, recall, F1-score, and AUC, for both training and test sets over your M runs. Plot the ROC and report the confusion matrix for training and testing in one of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08195cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Learning: L1-penalized SVM\n",
    "def supervised_learning(X_train, y_train, X_test, y_test):\n",
    "    param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "    l1_svm = LinearSVC(penalty='l1', dual=False, max_iter=5000)\n",
    "    grid = GridSearchCV(l1_svm, param_grid, cv=5)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid.best_estimator_\n",
    "    y_train_pred = best_model.predict(X_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "    train_scores = {\n",
    "        'accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'precision': precision_score(y_train, y_train_pred),\n",
    "        'recall': recall_score(y_train, y_train_pred),\n",
    "        'f1_score': f1_score(y_train, y_train_pred),\n",
    "        'auc': roc_auc_score(y_train, y_train_pred)\n",
    "    }\n",
    "\n",
    "    test_scores = {\n",
    "        'accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1_score': f1_score(y_test, y_test_pred),\n",
    "        'auc': roc_auc_score(y_test, y_test_pred)\n",
    "    }\n",
    "\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012fb61",
   "metadata": {},
   "source": [
    "#### ii. Semi-Supervised Learning/ Self-training: select 50% of the positive class along with 50% of the negative class in the training set as labeled data and the rest as unlabelled data. You can select them randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969de7b2",
   "metadata": {},
   "source": [
    "#### A. Train an L1-penalized SVM to classify the labeled data Use normalized data. Choose the penalty parameter using 5 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d4a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_list = []\n",
    "test_scores_list = []\n",
    "\n",
    "for i in range(M):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    X_labeled, X_unlabeled, y_labeled, y_unlabeled = train_test_split(X_train, y_train, test_size=0.5, stratify=y_train)\n",
    "\n",
    "    param_grid = {'C': np.logspace(-3, 3, 7)}\n",
    "    l1_svm = LinearSVC(penalty='l1', dual=False, max_iter=5000)\n",
    "    grid = GridSearchCV(l1_svm, param_grid, cv=5)\n",
    "    grid.fit(X_labeled, y_labeled)\n",
    "\n",
    "    while len(X_unlabeled) > 0:\n",
    "        best_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1b9f5",
   "metadata": {},
   "source": [
    "#### B. Find the unlabeled data point that is the farthest to the decision boundary of the SVM. Let the SVM label it (ignore its true label), and add it to the labeled data, and retrain the SVM. Continue this process until all unlabeled data are used. Test the  nal SVM on the test data and the average accuracy, precision, recall, F1-score, and AUC, for both training and test sets over your M runs. Plot the ROC and report the confusion matrix for training and testing in one of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e09689f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e5a0c9e",
   "metadata": {},
   "source": [
    "#### iii. Unsupervised Learning: Run k-means algorithm on the whole training set. Ignore the labels of the data, and assume k = 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0aafb6",
   "metadata": {},
   "source": [
    "#### A. Run the k-means algorithm multiple times. Make sure that you initialize the algoritm randomly. How do you make sure that the algorithm was not trapped in a local minimum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38b847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "734b1f22",
   "metadata": {},
   "source": [
    "#### B. Compute the centers of the two clusters and  find the closest 30 data points to each center. Read the true labels of those 30 data points and take a majority poll within them. The majority poll becomes the label predicted by k-means for the members of each cluster. Then compare the labels provided by k-means with the true labels of the training data and report the average accuracy, precision, recall, F1-score, and AUC over M runs, and ROC and the confusion matrix for one of the runs. [<sup>1</sup>](#fn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95501a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af25bfc8",
   "metadata": {},
   "source": [
    "#### C. Classify test data based on their proximity to the centers of the clusters. Report the average accuracy, precision, recall, F1-score, and AUC over M runs, and ROC and the confusion matrix for one of the runs for the test data.[<sup>2</sup>](#fn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d843c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d040cfe",
   "metadata": {},
   "source": [
    "#### iv. Spectral Clustering: Repeat 1(b)iii using spectral clustering, which is clustering based on kernels.3 Research what spectral clustering is. Use RBF kernel with gamma=1 or  nd a gamma for which the two clutsres have the same balance as the one in original data set (if the positive class has p and the negative class has n samples, the two clusters must have p and n members). Do not label data based on their proximity to cluster center, because spectral clustering may give you non-convex clusters . Instead, use fit-predict method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d8b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9d9f35e",
   "metadata": {},
   "source": [
    "#### v. One can expect that supervised learning on the full data set works better than semi-supervised learning with half of the data set labeled.One can expect that unsupervised learning underperforms in such situations. Compare the results you obtained by those methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b4e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18b4f786",
   "metadata": {},
   "source": [
    "### 2. Active Learning Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0c9a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7779614",
   "metadata": {},
   "source": [
    "#### (a) Download the banknote authentication Data Set from: https://archive.ics.uci.edu/ml/datasets/banknote+authentication. Choose 472 data points randomly as the test set, and the remaining 900 points as the training set. This is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f578972c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffcc630a",
   "metadata": {},
   "source": [
    "#### (b) Repeat each of the following two procedures 50 times. You will have 50 errors for 90 SVMs per each procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93af5ea",
   "metadata": {},
   "source": [
    "#### i. Train a SVM with a pool of 10 randomly selected data points from the training set using linear kernel and L1 penalty. Select the penalty parameter using 5-fold cross validation. [<sup>4</sup>](#fn4) Repeat this process by adding 10 other randomly selected data points to the pool, until you use all the 900 points. Do NOT replace the samples back into the training set at each step. Calculate the test error for each SVM. You will have 90 SVMs that were trained using 10, 20, 30, ... , 900 data points and their 90 test errors. You have implemented passive learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6127dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc9c22f5",
   "metadata": {},
   "source": [
    "#### ii. Train a SVM with a pool of 10 randomly selected data points from the training set [<sup>5</sup>](#fn5)  using linear kernel and L1 penalty. Select the parameters of the SVM with 5-fold cross validation. Choose the 10 closest data points in the training set to the hyperplane of the SVM6 and add them to the pool. Do not replace the samples back into the training set. Train a new SVM using the pool. Repeat this process until all training data is used. You will have 90 SVMs that were trained using 10, 20, 30,..., 900 data points and their 90 test errors. You have implemented active learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bcf083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e9607f6",
   "metadata": {},
   "source": [
    "#### (c) Average the 50 test errors for each of the incrementally trained 90 SVMs in 2(b)i and 2(b)ii. By doing so, you are performing a Monte Carlo simulation. Plot average test error versus number of training instances for both active and passive learners on the same  gure and report your conclusions. Here, you are actually obtaining a learning curve by Monte-Carlo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b9a61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371a71e7",
   "metadata": {},
   "source": [
    "##### <span style='color:green '> Footnote section <span>   \n",
    "\n",
    "<span id=\"fn1\"> 1.Here we are using k-means as a classi er. The closest 30 data points to each center are labeled by experts, so as to use k-means for classi cation. Obviously, this is a naive approach. <span>     \n",
    "<span id=\"fn2\"> 2. K-means algorithm does not provide probabilities, so one can use the distances from cluster center and pass them through a softmax to calculate probabilities. Alternatively, one can calculate the ROC curve by varying the threshold for majority polling. Usually, a majority is achieved when t = 50% of the data are in\n",
    "a class. one can vary t and obtain an ROC curve. <span>   \n",
    "<span id=\"fn3\"> 3. Because Spectral Clustering will not give you cluster centers, instead of considering 30 closest data points to the center, consider labeling based on either 30 randomly selected data points or the entire points in each cluster. Also, for ROC curves, you can vary the threshold of majority polling to obtain an ROC. <span>   \n",
    "<span id=\"fn4\"> 4. How to choose parameter ranges for SVMs? One can use wide ranges for the parameters and a  negrid (e.g. 1000 points) for cross validation; however,this method may be computationally expensive. An alternative way is to train the SVM with very large and very small parameters on the whole training data and  nd very large and very small parameters for which the training accuracy is not below a threshold (e.g.,70%). Then one can select a  xed number of parameters (e.g., 20) between those points for cross validation. For the penalty parameter, usually one has to consider increments in log( ). For example, if one found that\n",
    "the accuracy of a support vector machine will not be below 70% for     = 10􀀀3 and   = 106, one has to choose log( ) 2 f􀀀3;􀀀2; : : : ; 4; 5; 6g. For the Gaussian Kernel parameter, one usually chooses linear increments,e.g.2 f:1; :2; : : : ; 2g. When both   and   are to be chosen using cross-validation, combinations of very small and very large  's and  's that keep the accuracy above a threshold (e.g.70%) can be used to determine the ranges for  and. Please note that these are very rough rules of thumb, not general procedures. <span>  \n",
    "<span id=\"fn5\"> 5. If all selected data points are from one class, select another set of 10 data points randomly.<span>   \n",
    "<span id=\"fn6\"> 6. You may use the result from linear algebra about the distance of a point from a hyperplane.<span>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d8baf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
